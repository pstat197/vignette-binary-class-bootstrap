---
title: "Application of Bootstrap Resampling on Student Mental Health Data"
subtitle: "Bootstrapping for Binary Classification Models"
author: "Luke Fields, Thomas Shi, Lily Li, Dingan Jiang"
published-title: "Updated"
editor: visual
format: html
code-copy: true
execute:
  message: false
  warning: false
  echo: false
  cache: true
---

## Importance of Mental Health

Before we delve into the specific code and models we implemented to describe the importance of bootstrapping, we probably should talk about the importance of our data set. We all feel quite passionately about the importance of mental health within UCSB students, and what better way to gain more insight on such a critical topic than to analyze it with Data Science techniques. Certain students may be experiencing untreated mental health problems without even knowing, and their friends, family, and especially self might want to be aware of this so they can improve their condition. How awesome would it be if we could leverage machine learning and statistical models to provide some positive assistance to the mental health issue in today's college students? That is what we aim to do in this vignette, but there lies an issue: we do not have a lot of data.

## Preprocessing, Outliers, and Data Findings

Binary categorical variables were factorized, survey timestamp was removed, and year was converted to a numeric variable. Stratified sampling was done for data splits due to imbalance in our outcome variables; in other words, less students reported having mental illness or reported seeking help. Survey data shows that underclassmen were surveyed more than upperclassmen and had higher rates of mental illness compared to upperclassmen.

## Exploratory Data Analysis

![](images/anxiety.png)

The graph shows that the majority of students have GPA between 3.00 and 4.00. Students who respond that they suffer from anxiety do not have a low gap. As a result, we can infer that there isn't much of a connection between anxiety and a high or low GPA.

![](images/depression.png)

Students who reported having depression also revealed the same result. These GPA-high students experience depression as well. We can suggest that there is also no strong relationship between depression and GPAs. Other elements, such as interactions with family or friends, the stress of maintaining a student budget and living expenses, and the pressure of looking for internships and jobs, can contribute to depression and anxiety.

![](images/depression_age.png)\
![](images/anxiety_age-01.png)

Two graphs above show density distribution by age for anxiety and depression. Graphs capture the same pattern as a U shape, and the number of people aged 18 and 24 indicating anxiety and depression are the most. There is a observation that could account for this phenomenon. Freshmen may feel uneasy in their new environment because they are unfamiliar with university policies and programs.

![![](images/year2.png)](images/year1.png)

School year frequency also shows the same rule for depression and anxiety. The number of students replying to have depression and anxiety increases from year one and raise to peaks in year three. ​​Finding a full-time job and applying to graduate programs may put pressure on junior students. This may explain why junior students have the largest group of students having depression or anxiety.

Below is the correlation plot between each variable

![](images/corrplot.png)

## Application of Bootstrapping

Since we have a small dataset, we can not sample without replacement since this would decrease our population size for subsequent samples and increase bias. Thus we can use bootstrapping to get a better representation of our data for analysis of shape, variance, coeeficents, and confidence intervals. By sampling with replacement, we can infer metrics on the population with reduced error.

## Results and Confidence Intervals

We are using 1000 bootstrap samples to provide a 95% confidence interval of prediction accuracies of students with mental illness. By providing a confidence interval, we get an averaged prediction accuracy from 1000 samples that is less bias, and we are able to see a wide range that our prediction accuracy can stretch from. Random forests and other bagging methods utilize bootstrap methods in their algorithms to take take subsets of data with replacement. Therefore, we can try bootstraping to get a better understanding of metrics using other models (logistic regression in this case). On depresion, bootstrapping with 1000 replications gives us an accuracy of 0.8, bias of 0.02677731, and std. error of 0.07158341. Looking at the distribution of prediction accuarcies, it seems to follow a normal distribution where predictions of about 0.8 had the highest frequency. There are few outliers with acuracies lower than 0.6 and others that were near 1. The data given gives low prediction accuracy for anxiety, possibly due to the difficulty of predicting thir outcome with the survey data we have. Accuracy rate is 0.5666667 with bias of 0.06373458 and std. error of 0.09111097. The 95 % CI is (0.3333, 0.6774).

## Tree Models
Using bootstrapping in boosted trees, depression predictions have 0.7808617 accuracy and ROC AUC = 0.7792286, which tells us that the model was able to use the data to distinguish between binary classes with moderate strength. Once again, anxiety has proven to be difficult t o predict with a 0.5558013 accuracy and ROC AUC = 0.4604968, indicating that the model can not distinguish between binary classes with our data.

## Final Remarks
While more data trains a stronger model, some situations make it difficult to collect usable and reliable data. Reusing the data over and over again for collecting accurate metrics almost sounds too good to be true. By utilizing bootstrap resampling on student-collected data and making little assumptions about the distribution, we have proven that depression can be predicted with a moderately strong accuracy. Thus, an application like this would benefit universities in addressing mental health concerns.